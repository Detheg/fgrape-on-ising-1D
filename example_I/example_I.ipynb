{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26661a6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a1c7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"./../feedback-grape\"))\n",
    "sys.path.append(os.path.abspath(\"./../\"))\n",
    "\n",
    "# ruff: noqa\n",
    "from feedback_grape.fgrape import optimize_pulse, evaluate_on_longer_time\n",
    "from helpers import (\n",
    "    init_grape_protocol,\n",
    "    init_fgrape_protocol,\n",
    "    test_implementations,\n",
    "    generate_random_state,\n",
    "    generate_random_initial_state\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from library.utils.FgResult_to_dict import FgResult_to_dict\n",
    "import json\n",
    "\n",
    "test_implementations()\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b95a59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical parameters\n",
    "# (attention! #elements in density matrix grow as 4^n*N_chains)\n",
    "n = 2 # number of qubits per chain (>= 2)\n",
    "N_chains = 2 # Number of parallel chains to simulate\n",
    "gamma = 0.25 # Decay constant\n",
    "\n",
    "assert n >= 2, \"Chain lengths must be at least 2.\"\n",
    "\n",
    "# Training and evaluation parameters\n",
    "training_params = {\n",
    "    \"N_samples\": 3, # Number of random initial states to sample\n",
    "    \"N_training_iterations\": 1000, # Number of training iterations\n",
    "    \"learning_rate\": 0.01, # Learning rate\n",
    "    \"convergence_threshold\": 1e-6,\n",
    "    \"batch_size\": 8,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"evaluation_time_steps\": 200,\n",
    "}\n",
    "\n",
    "# Architectures to test\n",
    "do_test_grape = True\n",
    "do_test_lut = True\n",
    "do_test_rnn = True\n",
    "\n",
    "# Parameters to test\n",
    "\n",
    "#num_time_steps : Number of time steps in the control pulse\n",
    "#lut_depth : Depth of the lookup table for feedback\n",
    "#reward_weights: Weights for the reward at each time step. Default only weights last timestep [0, 0, ... 0, 1]\n",
    "\n",
    "experiments = [ # (timesteps, lut_depth, reward_weights)\n",
    "    (1,1,[1]),\n",
    "    (2,1,[0,1]),\n",
    "    (2,1,[1,1]),\n",
    "    (3,1,[0,0,1]),\n",
    "    (3,1,[0,1,1]),\n",
    "    (3,1,[1,1,1]),\n",
    "\n",
    "    (1,1,[1]),\n",
    "    (2,2,[0,1]),\n",
    "    (2,2,[1,1]),\n",
    "    (3,2,[0,0,1]),\n",
    "    (3,2,[0,1,1]),\n",
    "    (3,2,[1,1,1]),\n",
    "    (3,3,[0,0,1]),\n",
    "    (3,3,[0,1,1]),\n",
    "    (3,3,[1,1,1]),\n",
    "]\n",
    "\n",
    "for t, l, weights in experiments:\n",
    "    assert type(t) == int and t >= 1, \"Number of time steps must be a positive integer.\"\n",
    "    assert type(l) == int and l >= 1, \"LUT depth must be a positive integer.\"\n",
    "    assert len(weights) == t, \"Length of weights must equal number of time steps.\"\n",
    "    assert l <= t, \"LUT depth cannot exceed number of time steps.\"\n",
    "    for w in weights:\n",
    "        assert type(w) == int and 0 <= w <= 9, \"Weights must be integers between 0 and 9 to save as single character in filename.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcac0ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating num_time_steps=1, lut_depth=1, reward_weights=[1]\n",
      "Optimizing grape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:20<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:31<00:00, 10.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating num_time_steps=2, lut_depth=1, reward_weights=[0, 1]\n",
      "Optimizing grape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:14<00:00, 24.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:29<00:00, 29.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:33<00:00, 31.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating num_time_steps=2, lut_depth=1, reward_weights=[1, 1]\n",
      "Optimizing grape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:15<00:00, 25.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUT for t=2, l=1, and weights=11 already trained, skipping training.\n",
      "Training RNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:33<00:00, 31.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating num_time_steps=3, lut_depth=1, reward_weights=[0, 0, 1]\n",
      "Optimizing grape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:15<00:00, 45.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:39<00:00, 53.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:46<00:00, 55.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating num_time_steps=3, lut_depth=1, reward_weights=[0, 1, 1]\n",
      "Optimizing grape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:17<00:00, 45.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:39<00:00, 53.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:46<00:00, 55.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating num_time_steps=3, lut_depth=1, reward_weights=[1, 1, 1]\n",
      "Optimizing grape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:19<00:00, 46.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:43<00:00, 54.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:48<00:00, 56.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating num_time_steps=1, lut_depth=1, reward_weights=[1]\n",
      "Grape for t=1 and weights=1 already optimized, skipping optimization.\n",
      "LUT for t=1, l=1, and weights=1 already trained, skipping training.\n",
      "RNN for t=1 and weights=1 already trained, skipping training.\n",
      "Evaluating num_time_steps=2, lut_depth=2, reward_weights=[0, 1]\n",
      "Grape for t=2 and weights=01 already optimized, skipping optimization.\n",
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:29<00:00, 29.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN for t=2 and weights=01 already trained, skipping training.\n",
      "Evaluating num_time_steps=2, lut_depth=2, reward_weights=[1, 1]\n",
      "Grape for t=2 and weights=11 already optimized, skipping optimization.\n",
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:32<00:00, 30.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN for t=2 and weights=11 already trained, skipping training.\n",
      "Evaluating num_time_steps=3, lut_depth=2, reward_weights=[0, 0, 1]\n",
      "Grape for t=3 and weights=001 already optimized, skipping optimization.\n",
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:45<00:00, 55.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN for t=3 and weights=001 already trained, skipping training.\n",
      "Evaluating num_time_steps=3, lut_depth=2, reward_weights=[0, 1, 1]\n",
      "Grape for t=3 and weights=011 already optimized, skipping optimization.\n",
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:43<00:00, 54.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN for t=3 and weights=011 already trained, skipping training.\n",
      "Evaluating num_time_steps=3, lut_depth=2, reward_weights=[1, 1, 1]\n",
      "Grape for t=3 and weights=111 already optimized, skipping optimization.\n",
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:47<00:00, 55.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN for t=3 and weights=111 already trained, skipping training.\n",
      "Evaluating num_time_steps=3, lut_depth=3, reward_weights=[0, 0, 1]\n",
      "Grape for t=3 and weights=001 already optimized, skipping optimization.\n",
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:47<00:00, 55.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN for t=3 and weights=001 already trained, skipping training.\n",
      "Evaluating num_time_steps=3, lut_depth=3, reward_weights=[0, 1, 1]\n",
      "Grape for t=3 and weights=011 already optimized, skipping optimization.\n",
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:48<00:00, 56.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN for t=3 and weights=011 already trained, skipping training.\n",
      "Evaluating num_time_steps=3, lut_depth=3, reward_weights=[1, 1, 1]\n",
      "Grape for t=3 and weights=111 already optimized, skipping optimization.\n",
      "Training LUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:50<00:00, 56.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN for t=3 and weights=111 already trained, skipping training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for num_time_steps, lut_depth, reward_weights in experiments:\n",
    "    print(f\"Evaluating num_time_steps={num_time_steps}, lut_depth={lut_depth}, reward_weights={reward_weights}\")\n",
    "    weights_str = \"\".join([str(w) for w in reward_weights])\n",
    "    state_callable1 = lambda key: generate_random_initial_state(key, N_chains=N_chains)\n",
    "    state_callable2 = lambda key: generate_random_state(key, N_chains=N_chains)\n",
    "    \n",
    "    if do_test_grape:\n",
    "        if os.path.exists(f\"./optimized_architectures/grape_t={num_time_steps}_s={training_params[\"N_samples\"]}_w={weights_str}.json\"):\n",
    "            print(f\"Grape for t={num_time_steps} and weights={weights_str} already optimized, skipping optimization.\")\n",
    "        else:\n",
    "            print(\"Optimizing grape\")\n",
    "\n",
    "            best_result = None\n",
    "            fidelities_each = []\n",
    "            for s in tqdm(range(training_params[\"N_samples\"])):\n",
    "                system_params = init_grape_protocol(jax.random.PRNGKey(s), n, N_chains, gamma)\n",
    "                \n",
    "                # Optimize GRAPE\n",
    "                try: # Catch any errors during optimization, as we may sometimes encounter numerical issues\n",
    "                    result = optimize_pulse(\n",
    "                        U_0=state_callable1,\n",
    "                        C_target=state_callable2,\n",
    "                        system_params=system_params,\n",
    "                        num_time_steps=num_time_steps,\n",
    "                        reward_weights=reward_weights,\n",
    "                        mode=\"no-measurement\",\n",
    "                        goal=\"fidelity\",\n",
    "                        max_iter=training_params[\"N_training_iterations\"],\n",
    "                        convergence_threshold=training_params[\"convergence_threshold\"],\n",
    "                        learning_rate=training_params[\"learning_rate\"],\n",
    "                        evo_type=\"density\",\n",
    "                        batch_size=training_params[\"batch_size\"],\n",
    "                        eval_batch_size=training_params[\"eval_batch_size\"],\n",
    "                    )\n",
    "\n",
    "                    if best_result is None or result.final_fidelity > best_result.final_fidelity:\n",
    "                        best_result = result\n",
    "\n",
    "                    fidelities_each.append(float(result.final_fidelity))\n",
    "                except Exception as e:\n",
    "                    if \"Argument rho0 is not hermitian.\" in str(e):\n",
    "                        print(f'Sample {s} failed with error: \"Argument rho0 is not hermitian.\"')\n",
    "                    else:\n",
    "                        print(f\"Sample {s} failed with error: {e}\")\n",
    "                    continue\n",
    "\n",
    "            if best_result is not None:\n",
    "                with open(f\"./optimized_architectures/grape_t={num_time_steps}_s={training_params[\"N_samples\"]}_w={weights_str}.json\", \"w\") as f:\n",
    "                    json.dump(FgResult_to_dict(best_result), f)\n",
    "                \n",
    "                try:\n",
    "                    result = evaluate_on_longer_time(\n",
    "                        U_0 = state_callable1,\n",
    "                        C_target = state_callable2,\n",
    "                        system_params = system_params,\n",
    "                        optimized_trainable_parameters = result.optimized_trainable_parameters,\n",
    "                        num_time_steps = training_params[\"evaluation_time_steps\"],\n",
    "                        evo_type = \"density\",\n",
    "                        goal = \"fidelity\",\n",
    "                        eval_batch_size = training_params[\"eval_batch_size\"],\n",
    "                        mode = \"no-measurement\",\n",
    "                    )\n",
    "\n",
    "                    fidelities_grape = result.fidelity_each_timestep\n",
    "\n",
    "                    jnp.savez(f\"./evaluation_results/grape_t={num_time_steps}_s={training_params[\"N_samples\"]}_w={weights_str}.npz\", fidelities_grape=jnp.array(fidelities_grape))\n",
    "                except Exception as e:\n",
    "                    if \"Argument rho0 is not hermitian.\" in str(e):\n",
    "                        print(f'Evaluation on longer time failed with error: \"Argument rho0 is not hermitian.\"')\n",
    "                    else:\n",
    "                        print(f\"Evaluation on longer time failed with error: {e}\")\n",
    "\n",
    "            with open(f\"./optimized_architectures/grape_t={num_time_steps}_s={training_params[\"N_samples\"]}_w={weights_str}_training_data.json\", \"w\") as f:\n",
    "                training_data = {\n",
    "                    \"fidelities_each_sample\": fidelities_each,\n",
    "                    \"average_fidelity\": float(jnp.mean(jnp.array(fidelities_each))),\n",
    "                    \"training_params\": training_params,\n",
    "                }\n",
    "                json.dump(training_data, f)\n",
    "    \n",
    "    if do_test_lut:\n",
    "        if os.path.exists(f\"./optimized_architectures/lut_t={num_time_steps}_l={lut_depth}_s={training_params[\"N_samples\"]}_w={weights_str}.json\"):\n",
    "            print(f\"LUT for t={num_time_steps}, l={lut_depth}, and weights={weights_str} already trained, skipping training.\")\n",
    "        else:\n",
    "            print(\"Training LUT\")\n",
    "\n",
    "            best_result = None\n",
    "            fidelities_each = []\n",
    "            for s in tqdm(range(training_params[\"N_samples\"])):\n",
    "                system_params = init_fgrape_protocol(jax.random.PRNGKey(s), n, N_chains, gamma)\n",
    "\n",
    "                # Train LUT\n",
    "                try: # Catch any errors during optimization, as we may sometimes encounter numerical issues\n",
    "                    result = optimize_pulse(\n",
    "                        U_0=state_callable1,\n",
    "                        C_target=state_callable2,\n",
    "                        system_params=system_params,\n",
    "                        num_time_steps=num_time_steps,\n",
    "                        lut_depth=lut_depth,\n",
    "                        reward_weights=reward_weights,\n",
    "                        mode=\"lookup\",\n",
    "                        goal=\"fidelity\",\n",
    "                        max_iter=training_params[\"N_training_iterations\"],\n",
    "                        convergence_threshold=training_params[\"convergence_threshold\"],\n",
    "                        learning_rate=training_params[\"learning_rate\"],\n",
    "                        evo_type=\"density\",\n",
    "                        batch_size=training_params[\"batch_size\"],\n",
    "                        eval_batch_size=training_params[\"eval_batch_size\"],\n",
    "                    )\n",
    "\n",
    "                    if best_result is None or result.final_fidelity > best_result.final_fidelity:\n",
    "                        best_result = result\n",
    "\n",
    "                    fidelities_each.append(float(result.final_fidelity))\n",
    "                except Exception as e:\n",
    "                    if \"Argument rho0 is not hermitian.\" in str(e):\n",
    "                        print(f'Sample {s} failed with error: \"Argument rho0 is not hermitian.\"')\n",
    "                    else:\n",
    "                        print(f\"Sample {s} failed with error: {e}\")\n",
    "                    continue\n",
    "\n",
    "            if best_result is not None:\n",
    "                with open(f\"./optimized_architectures/lut_t={num_time_steps}_l={lut_depth}_s={training_params[\"N_samples\"]}_w={weights_str}.json\", \"w\") as f:\n",
    "                    json.dump(FgResult_to_dict(best_result), f)\n",
    "\n",
    "                try:\n",
    "                    result = evaluate_on_longer_time(\n",
    "                        U_0 = state_callable1,\n",
    "                        C_target = state_callable2,\n",
    "                        system_params = system_params,\n",
    "                        optimized_trainable_parameters = result.optimized_trainable_parameters,\n",
    "                        num_time_steps = training_params[\"evaluation_time_steps\"],\n",
    "                        evo_type = \"density\",\n",
    "                        goal = \"fidelity\",\n",
    "                        eval_batch_size = training_params[\"eval_batch_size\"],\n",
    "                        mode = \"lookup\",\n",
    "                    )\n",
    "\n",
    "                    fidelities_lut = result.fidelity_each_timestep\n",
    "\n",
    "                    jnp.savez(f\"./evaluation_results/lut_t={num_time_steps}_l={lut_depth}_s={training_params[\"N_samples\"]}_w={weights_str}.npz\", fidelities_lut=jnp.array(fidelities_lut))\n",
    "                except Exception as e:\n",
    "                    if \"Argument rho0 is not hermitian.\" in str(e):\n",
    "                        print(f'Evaluation on longer time failed with error: \"Argument rho0 is not hermitian.\"')\n",
    "                    else:\n",
    "                        print(f\"Evaluation on longer time failed with error: {e}\")\n",
    "\n",
    "            with open(f\"./optimized_architectures/lut_t={num_time_steps}_l={lut_depth}_s={training_params[\"N_samples\"]}_w={weights_str}_training_data.json\", \"w\") as f:\n",
    "                training_data = {\n",
    "                    \"fidelities_each_sample\": fidelities_each,\n",
    "                    \"average_fidelity\": float(jnp.mean(jnp.array(fidelities_each))),\n",
    "                    \"training_params\": training_params,\n",
    "                }\n",
    "                json.dump(training_data, f)\n",
    "        \n",
    "    if do_test_rnn:\n",
    "        if os.path.exists(f\"./optimized_architectures/rnn_t={num_time_steps}_s={training_params[\"N_samples\"]}_w={weights_str}.json\"):\n",
    "            print(f\"RNN for t={num_time_steps} and weights={weights_str} already trained, skipping training.\")\n",
    "        else:\n",
    "            print(\"Training RNN\")\n",
    "\n",
    "            best_result = None\n",
    "            fidelities_each = []\n",
    "            for s in tqdm(range(training_params[\"N_samples\"])):\n",
    "                system_params = init_fgrape_protocol(jax.random.PRNGKey(s), n, N_chains, gamma)\n",
    "\n",
    "                # Train RNN\n",
    "                try: # Catch any errors during optimization, as we may sometimes encounter numerical issues\n",
    "                    result = optimize_pulse(\n",
    "                        U_0=state_callable1,\n",
    "                        C_target=state_callable2,\n",
    "                        system_params=system_params,\n",
    "                        num_time_steps=num_time_steps,\n",
    "                        lut_depth=lut_depth,\n",
    "                        reward_weights=reward_weights,\n",
    "                        mode=\"nn\",\n",
    "                        goal=\"fidelity\",\n",
    "                        max_iter=training_params[\"N_training_iterations\"],\n",
    "                        convergence_threshold=training_params[\"convergence_threshold\"],\n",
    "                        learning_rate=training_params[\"learning_rate\"],\n",
    "                        evo_type=\"density\",\n",
    "                        batch_size=training_params[\"batch_size\"],\n",
    "                        eval_batch_size=training_params[\"eval_batch_size\"],\n",
    "                    )\n",
    "\n",
    "                    if best_result is None or result.final_fidelity > best_result.final_fidelity:\n",
    "                        best_result = result\n",
    "\n",
    "                    fidelities_each.append(float(result.final_fidelity))\n",
    "                except Exception as e:\n",
    "                    if \"Argument rho0 is not hermitian.\" in str(e):\n",
    "                        print(f'Sample {s} failed with error: \"Argument rho0 is not hermitian.\"')\n",
    "                    else:\n",
    "                        print(f\"Sample {s} failed with error: {e}\")\n",
    "                    continue\n",
    "\n",
    "            if best_result is not None:\n",
    "                with open(f\"./optimized_architectures/rnn_t={num_time_steps}_s={training_params[\"N_samples\"]}_w={weights_str}.json\", \"w\") as f:\n",
    "                    json.dump(FgResult_to_dict(best_result), f)\n",
    "\n",
    "                try:\n",
    "                    result = evaluate_on_longer_time(\n",
    "                        U_0 = state_callable1,\n",
    "                        C_target = state_callable2,\n",
    "                        system_params = system_params,\n",
    "                        optimized_trainable_parameters = result.optimized_trainable_parameters,\n",
    "                        num_time_steps = training_params[\"evaluation_time_steps\"],\n",
    "                        evo_type = \"density\",\n",
    "                        goal = \"fidelity\",\n",
    "                        eval_batch_size = training_params[\"eval_batch_size\"],\n",
    "                        mode = \"nn\",\n",
    "                    )\n",
    "\n",
    "                    fidelities_rnn = result.fidelity_each_timestep\n",
    "\n",
    "                    jnp.savez(f\"./evaluation_results/rnn_t={num_time_steps}_s={training_params[\"N_samples\"]}_w={weights_str}.npz\", fidelities_rnn=jnp.array(fidelities_rnn))\n",
    "                except Exception as e:\n",
    "                    if \"Argument rho0 is not hermitian.\" in str(e):\n",
    "                        print(f'Evaluation on longer time failed with error: \"Argument rho0 is not hermitian.\"')\n",
    "                    else:\n",
    "                        print(f\"Evaluation on longer time failed with error: {e}\")\n",
    "\n",
    "            with open(f\"./optimized_architectures/rnn_t={num_time_steps}_s={training_params[\"N_samples\"]}_w={weights_str}_training_data.json\", \"w\") as f:\n",
    "                training_data = {\n",
    "                    \"fidelities_each_sample\": fidelities_each,\n",
    "                    \"average_fidelity\": float(jnp.mean(jnp.array(fidelities_each))),\n",
    "                    \"training_params\": training_params,\n",
    "                }\n",
    "                json.dump(training_data, f)\n",
    "    \n",
    "    \n",
    "# Play a sound when done\n",
    "os.system('say \"done.\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0709b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
